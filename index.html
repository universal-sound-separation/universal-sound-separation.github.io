<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>
Universal Sound Separation
</title>
<link href="css/style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div class="container">
  <p>&nbsp;</p>
  <p><span class="title">Universal Sound Separation</span></p>
  <br />
  <table border="0" align="center" class="authors">
    <tr align="center">
      <td><a href="http://ilyakavalerov.com">Ilya Kavalerov<sup>1,2</sup></a></td>
      <td><a href="https://ai.google/research/people/ScottWisdom">Scott Wisdom<sup>1</sup></a></td>
      <td><a href="http://erdogan.org">Hakan Erdogan<sup>1</sup></a></td>
      <td><a href="https://ai.google/research/people/105050">Brian Patton<sup>1</sup></a></td>
      <td><a href="https://ai.google/research/people/KevinWilson">Kevin Wilson<sup>1</sup></a></td>
      <td><a href="http://jonathanleroux.org">Jonathan Le Roux<sup>3</sup></a></td>
      <td><a href="https://ai.google/research/people/106072">John R. Hershey<sup>1</sup></a></td>
    </tr>
  </table>
  <br />
  <table border="0" align="center" class="affiliations">
    <tr>
      <!--
      <td align="center"><img src="images/logo_research.png" height="40" alt=""/></td>
      -->
      <td align="left"><a href="https://research.google.com/"><sup>1</sup>Google Research</a></td>
    </tr>
  </table>
  <table border="0" align="center" class="affiliations">
  <tr>
    <td align="center"><a href="https://ece.umd.edu/"><sup>2</sup>University of Maryland</a></td>
    </tr>
  </table>
  <table border="0" align="center" class="affiliations">
  <tr>
    <td align="center"><a href="https://www.merl.com/"><sup>3</sup>Mitsubishi Electric Research Labs</a></td>
  </tr>
  </table>
  <br />
  <p><span class="section">Abstract</span></p>
  <p>Recent deep learning approaches have achieved impressive performance on speech enhancement and separation tasks. However, these approaches have not been investigated for separating mixtures of arbitrary sounds of different types, a task we refer to as universal sound separation, and it is unknown whether performance on speech tasks carries over to non-speech tasks. To study this question, we develop a universal dataset of mixtures containing arbitrary sounds, and use it to investigate the space of mask-based separation architectures, varying both the overall network architecture and the framewise analysis-synthesis basis for signal transformations. These network architectures include convolutional long short-term
memory networks and time-dilated convolution stacks inspired
by the recent success of time-domain enhancement networks like
ConvTasNet. For the latter architecture, we also propose novel
modifications that further improve separation performance. In
terms of the framewise analysis-synthesis basis, we explore using
either a short-time Fourier transform (STFT) or a learnable basis,
as used in ConvTasNet, and for both of these bases, we examine
the effect of window size. In particular, for STFTs, we find that
longer windows (25-50 ms) work best for speech/non-speech separation, while shorter windows (2.5 ms) work best for arbitrary
sounds. For learnable bases, shorter windows (2.5 ms) work best
on all tasks. Surprisingly, for universal sound separation, STFTs
outperform learnable bases. Our best methods produce an improvement in scale-invariant signal-to-distortion ratio of over 13 dB
for speech/non-speech separation and close to 10 dB for universal
sound separation.<br />
  </p>
  <p class="section">&nbsp;</p>

  <p>&nbsp;</p>
  <p class="section">Paper</p>
  <table border="0">
    <tbody>
      <tr>
        <td>&nbsp;</td>
        <td><p>&quot;Universal Sound Separation&quot;,<br />
            Ilya Kavalerov, Scott Wisdom, Hakan Erdogan, Brian Patton, Kevin Wilson, Jonathan Le Roux, John R. Hershey,<br />
            Proc. WASPAA, October 2019, New Paltz, NY.</a></p>
        <p>[<a href="https://arxiv.org/pdf/1905.03330.pdf">PDF</a>]</p></td>
      </tr>
    </tbody>
  </table>
  <br />
  <p class="section">Audio Demos</p>
  <table width="600" height="40" border="0">
      <td><a href="supplemental/speechenh/audio_demos.html">Speech Enhancement</a></td>
      <td><a href="supplemental/nonsp2/audio_demos.html">2-Source Universal Sound Separation</a></td>
      <td><a href="supplemental/nonsp3/audio_demos.html">3-Source Universal Sound Separation</a></td>
  </table>
  <p class="section">&nbsp;</p>
  <p class="section">Dataset Recipe</p>
  <table width="600" height="40" border="0">
    <td>Coming soon.</td>
  </table>
  <p class="section">&nbsp;</p>
  <p align="center" class="date">Last updated: Aug 2019</p>
</div>
</body>
</html>
